{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsp2znaQUAAc",
        "outputId": "b76e1401-2a51-41aa-c52e-21bd86318213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "file_name = \"NovoDataset2.csv\"\n",
        "test_size = 0.4\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/Mestrado/Projeto/LSTMLevel/data\"\n",
        "model_dir = \"/content/drive/MyDrive/Mestrado/Projeto/LSTMLevel/model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "423ZFbpMUKzT"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "\n",
        "def load_data(file_name):\n",
        "    data = pd.read_csv(Path(data_dir, file_name))\n",
        "    return data\n",
        "\n",
        "\n",
        "def save_data(df, file_name):\n",
        "    df.astype(float).to_csv(Path(data_dir, file_name), index=False)\n",
        "    return None\n",
        "\n",
        "def adicionar_coluna_trip(df):\n",
        "    label_column = []\n",
        "    num_anterior = df['Valvula.VALVE_SHUTOFF.L'][0]\n",
        "\n",
        "    for valor in df['Valvula.VALVE_SHUTOFF.L']:\n",
        "        if valor == 0 and num_anterior == 1:\n",
        "            label_column.append(1)\n",
        "        else:\n",
        "            label_column.append(0)\n",
        "\n",
        "        num_anterior = valor\n",
        "\n",
        "    df['Trip'] = label_column\n",
        "\n",
        "    return df\n",
        "\n",
        "def adicionar_coluna_label(df):\n",
        "    df['Label'] = df['Drum.V1.L']\n",
        "\n",
        "    return df\n",
        "\n",
        "def change_datetime(df):\n",
        "    data_atual = datetime.now()\n",
        "    segundos = [timedelta(seconds=i) for i in range(len(df))]\n",
        "    df['Datetime'] = data_atual + pd.to_timedelta(segundos)\n",
        "\n",
        "    return df\n",
        "\n",
        "def arredondar_dataframe(df, casas_decimais=3):\n",
        "    return df.round(casas_decimais)\n",
        "\n",
        "def create_features(df):\n",
        "    df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
        "\n",
        "    df = adicionar_coluna_trip(df)\n",
        "    df = adicionar_coluna_label(df)\n",
        "\n",
        "    df = df.drop(columns=['Datetime'])\n",
        "\n",
        "    contagem = (df['Trip'] == 1).sum()\n",
        "    print('{} eventos de trip'.format(contagem))\n",
        "    print('{} Max'.format(contagem.max()))\n",
        "\n",
        "    return df\n",
        "\n",
        "def rescale_data(df):\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler = scaler.fit(df)\n",
        "\n",
        "    df_scaled = pd.DataFrame(\n",
        "        scaler.transform(df),\n",
        "        index=df.index,\n",
        "        columns=df.columns)\n",
        "\n",
        "    joblib.dump(scaler, Path(model_dir, 'scaler_teste2_escrita.gz'))\n",
        "\n",
        "    return df_scaled\n",
        "\n",
        "def split_data(df, test_size):\n",
        "    train, test = train_test_split(df, test_size=test_size, shuffle=False)\n",
        "    return train, test\n",
        "\n",
        "def remove_features(df):\n",
        "    columns_to_remove = [\n",
        "        'Variaveis.TR1_RUIDO',\n",
        "        'Variaveis.TR2_RUIDO',\n",
        "        'Variaveis.TR3_RUIDO',\n",
        "        'Transmissor.TR1.OUT',\n",
        "        'Transmissor.TR2.OUT',\n",
        "        'Transmissor.TR3.OUT',\n",
        "        'Trip'\n",
        "    ]\n",
        "\n",
        "    return df.drop(columns=columns_to_remove)\n",
        "\n",
        "def aplicar_ruidos(dataset):\n",
        "    novo_dataset = dataset.copy()\n",
        "\n",
        "    for i in range(len(dataset)):\n",
        "        if np.random.rand() < 0.5:\n",
        "            colunas_ruido = np.random.choice(['Variaveis.TR1_RUIDO', 'Variaveis.TR2_RUIDO', 'Variaveis.TR3_RUIDO'], size=2, replace=False)\n",
        "            novo_dataset.loc[i, colunas_ruido] = True\n",
        "            novo_dataset.at[i, 'Variaveis.VOTACAO_TRANSMISSORES'] = novo_dataset.at[i, 'Transmissor.TR1.OUT']\n",
        "\n",
        "            for coluna in colunas_ruido:\n",
        "                novo_dataset.at[i, coluna] += np.random.uniform(0.01, 0.2)\n",
        "\n",
        "        elif np.random.rand() < 0.5:\n",
        "                coluna_w_s6 = 'Tubo.S6.W'\n",
        "                quantidade_registros_alterar = np.random.randint(1, 11)\n",
        "                valor_somar = np.random.randint(0, 2001)\n",
        "                novo_dataset.loc[i:i + quantidade_registros_alterar, coluna_w_s6] += valor_somar\n",
        "\n",
        "    return novo_dataset\n",
        "\n",
        "\n",
        "def prep_data(df, test_size, plot_df=False):\n",
        "    print(\"Starting with data preparation...\")\n",
        "\n",
        "    df = aplicar_ruidos(df)\n",
        "\n",
        "    df = change_datetime(df)\n",
        "    df = create_features(df)\n",
        "    df = remove_features(df)\n",
        "    df = arredondar_dataframe(df)\n",
        "\n",
        "    train_df, test_df = split_data(df, test_size)\n",
        "\n",
        "    if plot_df:\n",
        "        save_data(train_df, 'plot_df.csv')\n",
        "\n",
        "    train_df = rescale_data(train_df)\n",
        "    scaler = joblib.load(Path(model_dir, 'scaler.gz'))\n",
        "\n",
        "    test_df = pd.DataFrame(\n",
        "        scaler.transform(test_df),\n",
        "        index=test_df.index,\n",
        "        columns=test_df.columns)\n",
        "\n",
        "    save_data(train_df, 'train.csv')\n",
        "    save_data(test_df, 'test.csv')\n",
        "\n",
        "    print(\"Completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn84xkeSUmFc",
        "outputId": "3c0a127d-b6ac-441e-d51c-df5ed8dc0fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(135707, 56)\n",
            "Starting with data preparation...\n",
            "12 eventos de trip\n",
            "12 Max\n",
            "Completed.\n"
          ]
        }
      ],
      "source": [
        "df = load_data(file_name)\n",
        "print(df.shape)\n",
        "prep_data(df, test_size, validation_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsBDqgKRjMoK"
      },
      "outputs": [],
      "source": [
        "#Lstm Multivariate Multi-Step\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from pandas import DataFrame , concat\n",
        "from sklearn.metrics import mean_absolute_error , mean_squared_error\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "from numpy import mean , concatenate\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM,Activation\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#from keras.models import Sequential\n",
        "#from keras.layers import Dense\n",
        "#from keras.layers import LSTM\n",
        "\n",
        "from numpy import array , hstack\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnQEQ6AUUI-c",
        "outputId": "1d1c3755-4d77-44ea-88dd-0d44f07ac5c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Variaveis.H2O_QTD', 'Valvula.VALVE5.OP',\n",
            "       'Variaveis.VOTACAO_TRANSMISSORES', 'Valvula.VALVE_RESPIRO.OP',\n",
            "       'Valvula.VALVE_RESPIRO.L', 'StreamSend.FLARE.P', 'Valvula.VALVE3.OP',\n",
            "       'Valvula.VALVE3.L', 'StreamSend.SAIDA_GAS.P', 'Valvula.VALVE2.OP',\n",
            "       'Valvula.VALVE2.L', 'Valvula.VALVE1.OP', 'Valvula.VALVE1.L',\n",
            "       'Valvula.VALVE_SHUTOFF.OP', 'Valvula.VALVE_SHUTOFF.L',\n",
            "       'StreamSend.SAIDA_LIQUIDO.P', 'Valvula.VALVE4.OP', 'Valvula.VALVE4.L',\n",
            "       'StreamSend.SAIDA_VAZAMENTO.P', 'Valvula.VALVE5.L', 'Drum.V1.L',\n",
            "       'Drum.V1.P', 'Drum.V1.T', 'Tubo.S1.P', 'Tubo.S1.W', 'Tubo.S2.P',\n",
            "       'Tubo.S2.W', 'Tubo.S6.P', 'Tubo.S6.W', 'Tubo.S5.P', 'Tubo.S5.W',\n",
            "       'Tubo.S10.P', 'Tubo.S10.W', 'Tubo.S3.P', 'Tubo.S3.W', 'Tubo.S4.P',\n",
            "       'Tubo.S4.W', 'Tubo.S25.P', 'Tubo.S25.W', 'Tubo.S26.P', 'Tubo.S26.W',\n",
            "       'Tubo.S27.P', 'Tubo.S27.W', 'Tubo.S28.P', 'Tubo.S28.W',\n",
            "       'Controlador.PC1.OUT', 'Controlador.PID1.OUT', 'Controlador.PID2.OUT',\n",
            "       'Controlador.PID3.OUT', 'Label'],\n",
            "      dtype='object')\n",
            "Index(['Variaveis.H2O_QTD', 'Valvula.VALVE5.OP',\n",
            "       'Variaveis.VOTACAO_TRANSMISSORES', 'Valvula.VALVE_RESPIRO.OP',\n",
            "       'Valvula.VALVE_RESPIRO.L', 'StreamSend.FLARE.P', 'Valvula.VALVE3.OP',\n",
            "       'Valvula.VALVE3.L', 'StreamSend.SAIDA_GAS.P', 'Valvula.VALVE2.OP',\n",
            "       'Valvula.VALVE2.L', 'Valvula.VALVE1.OP', 'Valvula.VALVE1.L',\n",
            "       'Valvula.VALVE_SHUTOFF.OP', 'Valvula.VALVE_SHUTOFF.L',\n",
            "       'StreamSend.SAIDA_LIQUIDO.P', 'Valvula.VALVE4.OP', 'Valvula.VALVE4.L',\n",
            "       'StreamSend.SAIDA_VAZAMENTO.P', 'Valvula.VALVE5.L', 'Drum.V1.L',\n",
            "       'Drum.V1.P', 'Drum.V1.T', 'Tubo.S1.P', 'Tubo.S1.W', 'Tubo.S2.P',\n",
            "       'Tubo.S2.W', 'Tubo.S6.P', 'Tubo.S6.W', 'Tubo.S5.P', 'Tubo.S5.W',\n",
            "       'Tubo.S10.P', 'Tubo.S10.W', 'Tubo.S3.P', 'Tubo.S3.W', 'Tubo.S4.P',\n",
            "       'Tubo.S4.W', 'Tubo.S25.P', 'Tubo.S25.W', 'Tubo.S26.P', 'Tubo.S26.W',\n",
            "       'Tubo.S27.P', 'Tubo.S27.W', 'Tubo.S28.P', 'Tubo.S28.W',\n",
            "       'Controlador.PC1.OUT', 'Controlador.PID1.OUT', 'Controlador.PID2.OUT',\n",
            "       'Controlador.PID3.OUT', 'Label'],\n",
            "      dtype='object')\n",
            "0\n",
            "0\n",
            "(108565, 49)\n",
            "(108565, 1)\n",
            "(27142, 49)\n",
            "(27142, 1)\n"
          ]
        }
      ],
      "source": [
        "train_df = load_data('train.csv')\n",
        "test_df = load_data('test.csv')\n",
        "\n",
        "print(train_df.columns)\n",
        "print(test_df.columns)\n",
        "\n",
        "print(train_df.isna().sum().sum())\n",
        "print(test_df.isna().sum().sum())\n",
        "\n",
        "colunas_label = ['Label']\n",
        "\n",
        "X_train, y_train = np.array(train_df.loc[:, ~train_df.columns.isin(colunas_label)]), np.array(train_df[colunas_label])\n",
        "X_test, y_test = np.array(test_df.loc[:, ~test_df.columns.isin(colunas_label)]), np.array(test_df[colunas_label])\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZkzl0efURsq",
        "outputId": "95dbf3c0-ba57-4d77-a04e-c628e3e01d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_sequence.shape (108522, 30, 49)\n",
            "y_train_sequence.shape (108522, 15, 1)\n",
            "X_test_sequence.shape (27099, 30, 49)\n",
            "y_test_sequence.shape (27099, 15, 1)\n"
          ]
        }
      ],
      "source": [
        "def split_sequences(df_X, df_y, n_steps_in, n_steps_out):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(df_X)):\n",
        "        end_ix = i + n_steps_in\n",
        "        out_end_ix = end_ix + n_steps_out-1\n",
        "        if out_end_ix > len(df_X):\n",
        "            break\n",
        "        seq_x, seq_y = df_X[i:end_ix], df_y[end_ix-1:out_end_ix]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return array(X), array(y)\n",
        "\n",
        "n_steps_in, n_steps_out = 30, 15\n",
        "\n",
        "X_train_sequence, y_train_sequence = split_sequences(X_train, y_train, n_steps_in, n_steps_out)\n",
        "X_test_sequence, y_test_sequence = split_sequences(X_test, y_test, n_steps_in, n_steps_out)\n",
        "print (\"X_train_sequence.shape\" , X_train_sequence.shape)\n",
        "print (\"y_train_sequence.shape\" , y_train_sequence.shape)\n",
        "print (\"X_test_sequence.shape\" , X_test_sequence.shape)\n",
        "print (\"y_test_sequence.shape\" , y_test_sequence.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RPksErocdUI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Bidirectional, Dropout, Flatten\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError, Accuracy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def get_model(params, input_shape):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(units=params[\"lstm_units\"], return_sequences=False, input_shape=(n_steps_in, input_shape)))\n",
        "\t#model.add(LSTM(units=params[\"lstm_units\"], return_sequences=False, dropout=params[\"dropout\"]))\n",
        "\tmodel.add(Dense(n_steps_out))\n",
        "\n",
        "\tmodel.compile(loss=params[\"loss\"],\n",
        "              \toptimizer=params[\"optimizer\"],\n",
        "              \tmetrics=[RootMeanSquaredError(), MeanAbsoluteError()])\n",
        "\n",
        "\treturn model\n",
        "\n",
        "def get_model_2(params, input_shape):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Bidirectional(LSTM(units=64, return_sequences=True, input_shape=(n_steps_in, input_shape))))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Bidirectional(LSTM(units=32, return_sequences=True)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(16))\n",
        "\tmodel.add(Dense(n_steps_out))\n",
        "\n",
        "\tmodel.compile(loss=params[\"loss\"],\n",
        "              \toptimizer=params[\"optimizer\"],\n",
        "              \tmetrics=[RootMeanSquaredError(), MeanAbsoluteError()])\n",
        "\n",
        "\treturn model\n",
        "\n",
        "def get_model_gru(params, input_shape):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(GRU(64, input_shape=(n_steps_in, input_shape)))\n",
        "\tmodel.add(Dense(n_steps_out))\n",
        "\n",
        "\tmodel.compile(loss=params[\"loss\"],\n",
        "              \toptimizer=params[\"optimizer\"],\n",
        "              \tmetrics=[RootMeanSquaredError(), MeanAbsoluteError()])\n",
        "\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s63I7NfockQ5"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "\t\"loss\": \"mean_squared_error\",\n",
        "\t\"optimizer\": \"adam\",\n",
        "\t\"dropout\": 0.2,\n",
        "\t\"lstm_units\": 64,\n",
        "\t\"epochs\": 300,\n",
        "\t\"batch_size\": 128,\n",
        "\t\"es_patience\" : 10\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Versão do TensorFlow:\", tf.__version__)\n",
        "\n",
        "# Verifique a presença de uma GPU\n",
        "if tf.test.gpu_device_name():\n",
        "    print(\"GPU disponível:\", tf.test.gpu_device_name())\n",
        "else:\n",
        "    print(\"GPU não encontrada. Certifique-se de que está configurado corretamente.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM_CVkVJHSaH",
        "outputId": "cd9b54a7-f0f9-4322-fd2b-bfd5a542583c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versão do TensorFlow: 2.15.0\n",
            "GPU disponível: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg-ZYif4cms4",
        "outputId": "67b586f3-fbaa-4113-853f-e171b765ea2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "847/848 [============================>.] - ETA: 0s - loss: 0.0038 - root_mean_squared_error: 0.0617 - mean_absolute_error: 0.0323\n",
            "Epoch 1: val_root_mean_squared_error improved from inf to 0.00597, saving model to lstmlevel-2-escrita.epoch01-loss0.00597.hdf5\n",
            "848/848 [==============================] - 21s 16ms/step - loss: 0.0038 - root_mean_squared_error: 0.0616 - mean_absolute_error: 0.0323 - val_loss: 3.5609e-05 - val_root_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0043\n",
            "Epoch 2/300\n",
            " 11/848 [..............................] - ETA: 9s - loss: 4.2288e-04 - root_mean_squared_error: 0.0206 - mean_absolute_error: 0.0156"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "846/848 [============================>.] - ETA: 0s - loss: 3.3218e-04 - root_mean_squared_error: 0.0182 - mean_absolute_error: 0.0137\n",
            "Epoch 2: val_root_mean_squared_error improved from 0.00597 to 0.00536, saving model to lstmlevel-2-escrita.epoch02-loss0.00536.hdf5\n",
            "848/848 [==============================] - 12s 15ms/step - loss: 3.3192e-04 - root_mean_squared_error: 0.0182 - mean_absolute_error: 0.0137 - val_loss: 2.8733e-05 - val_root_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0038\n",
            "Epoch 3/300\n",
            "848/848 [==============================] - ETA: 0s - loss: 1.8691e-04 - root_mean_squared_error: 0.0137 - mean_absolute_error: 0.0102\n",
            "Epoch 3: val_root_mean_squared_error improved from 0.00536 to 0.00484, saving model to lstmlevel-2-escrita.epoch03-loss0.00484.hdf5\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 1.8691e-04 - root_mean_squared_error: 0.0137 - mean_absolute_error: 0.0102 - val_loss: 2.3443e-05 - val_root_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0033\n",
            "Epoch 4/300\n",
            "845/848 [============================>.] - ETA: 0s - loss: 1.3946e-04 - root_mean_squared_error: 0.0118 - mean_absolute_error: 0.0088\n",
            "Epoch 4: val_root_mean_squared_error did not improve from 0.00484\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 1.3947e-04 - root_mean_squared_error: 0.0118 - mean_absolute_error: 0.0088 - val_loss: 2.7196e-05 - val_root_mean_squared_error: 0.0052 - val_mean_absolute_error: 0.0039\n",
            "Epoch 5/300\n",
            "847/848 [============================>.] - ETA: 0s - loss: 1.1497e-04 - root_mean_squared_error: 0.0107 - mean_absolute_error: 0.0081\n",
            "Epoch 5: val_root_mean_squared_error did not improve from 0.00484\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 1.1493e-04 - root_mean_squared_error: 0.0107 - mean_absolute_error: 0.0081 - val_loss: 3.1386e-05 - val_root_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0040\n",
            "Epoch 6/300\n",
            "848/848 [==============================] - ETA: 0s - loss: 9.7175e-05 - root_mean_squared_error: 0.0099 - mean_absolute_error: 0.0074\n",
            "Epoch 6: val_root_mean_squared_error did not improve from 0.00484\n",
            "848/848 [==============================] - 12s 14ms/step - loss: 9.7175e-05 - root_mean_squared_error: 0.0099 - mean_absolute_error: 0.0074 - val_loss: 7.0354e-05 - val_root_mean_squared_error: 0.0084 - val_mean_absolute_error: 0.0066\n",
            "Epoch 7/300\n",
            "848/848 [==============================] - ETA: 0s - loss: 8.2664e-05 - root_mean_squared_error: 0.0091 - mean_absolute_error: 0.0068\n",
            "Epoch 7: val_root_mean_squared_error did not improve from 0.00484\n",
            "848/848 [==============================] - 11s 14ms/step - loss: 8.2664e-05 - root_mean_squared_error: 0.0091 - mean_absolute_error: 0.0068 - val_loss: 9.5405e-05 - val_root_mean_squared_error: 0.0098 - val_mean_absolute_error: 0.0089\n",
            "Epoch 8/300\n",
            "844/848 [============================>.] - ETA: 0s - loss: 7.1097e-05 - root_mean_squared_error: 0.0084 - mean_absolute_error: 0.0063\n",
            "Epoch 8: val_root_mean_squared_error did not improve from 0.00484\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 7.1070e-05 - root_mean_squared_error: 0.0084 - mean_absolute_error: 0.0063 - val_loss: 2.5717e-05 - val_root_mean_squared_error: 0.0051 - val_mean_absolute_error: 0.0039\n",
            "Epoch 9/300\n",
            "845/848 [============================>.] - ETA: 0s - loss: 6.9201e-05 - root_mean_squared_error: 0.0083 - mean_absolute_error: 0.0062\n",
            "Epoch 9: val_root_mean_squared_error improved from 0.00484 to 0.00439, saving model to lstmlevel-2-escrita.epoch09-loss0.00439.hdf5\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 6.9182e-05 - root_mean_squared_error: 0.0083 - mean_absolute_error: 0.0062 - val_loss: 1.9286e-05 - val_root_mean_squared_error: 0.0044 - val_mean_absolute_error: 0.0029\n",
            "Epoch 10/300\n",
            "846/848 [============================>.] - ETA: 0s - loss: 5.8966e-05 - root_mean_squared_error: 0.0077 - mean_absolute_error: 0.0057\n",
            "Epoch 10: val_root_mean_squared_error did not improve from 0.00439\n",
            "848/848 [==============================] - 12s 15ms/step - loss: 5.8942e-05 - root_mean_squared_error: 0.0077 - mean_absolute_error: 0.0057 - val_loss: 1.9790e-05 - val_root_mean_squared_error: 0.0044 - val_mean_absolute_error: 0.0032\n",
            "Epoch 11/300\n",
            "845/848 [============================>.] - ETA: 0s - loss: 5.6671e-05 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0056\n",
            "Epoch 11: val_root_mean_squared_error did not improve from 0.00439\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 5.6624e-05 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0056 - val_loss: 5.1227e-05 - val_root_mean_squared_error: 0.0072 - val_mean_absolute_error: 0.0060\n",
            "Epoch 12/300\n",
            "848/848 [==============================] - ETA: 0s - loss: 5.2950e-05 - root_mean_squared_error: 0.0073 - mean_absolute_error: 0.0054\n",
            "Epoch 12: val_root_mean_squared_error improved from 0.00439 to 0.00400, saving model to lstmlevel-2-escrita.epoch12-loss0.00400.hdf5\n",
            "848/848 [==============================] - 11s 12ms/step - loss: 5.2950e-05 - root_mean_squared_error: 0.0073 - mean_absolute_error: 0.0054 - val_loss: 1.6000e-05 - val_root_mean_squared_error: 0.0040 - val_mean_absolute_error: 0.0028\n",
            "Epoch 13/300\n",
            "847/848 [============================>.] - ETA: 0s - loss: 4.9362e-05 - root_mean_squared_error: 0.0070 - mean_absolute_error: 0.0052\n",
            "Epoch 13: val_root_mean_squared_error did not improve from 0.00400\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 4.9416e-05 - root_mean_squared_error: 0.0070 - mean_absolute_error: 0.0052 - val_loss: 3.3889e-05 - val_root_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0046\n",
            "Epoch 14/300\n",
            "848/848 [==============================] - ETA: 0s - loss: 4.7683e-05 - root_mean_squared_error: 0.0069 - mean_absolute_error: 0.0051\n",
            "Epoch 14: val_root_mean_squared_error did not improve from 0.00400\n",
            "848/848 [==============================] - 12s 14ms/step - loss: 4.7683e-05 - root_mean_squared_error: 0.0069 - mean_absolute_error: 0.0051 - val_loss: 4.5496e-05 - val_root_mean_squared_error: 0.0067 - val_mean_absolute_error: 0.0054\n",
            "Epoch 15/300\n",
            "844/848 [============================>.] - ETA: 0s - loss: 4.4546e-05 - root_mean_squared_error: 0.0067 - mean_absolute_error: 0.0050\n",
            "Epoch 15: val_root_mean_squared_error did not improve from 0.00400\n",
            "848/848 [==============================] - 11s 14ms/step - loss: 4.4532e-05 - root_mean_squared_error: 0.0067 - mean_absolute_error: 0.0050 - val_loss: 3.6481e-05 - val_root_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0048\n",
            "Epoch 16/300\n",
            "846/848 [============================>.] - ETA: 0s - loss: 4.1039e-05 - root_mean_squared_error: 0.0064 - mean_absolute_error: 0.0047\n",
            "Epoch 16: val_root_mean_squared_error improved from 0.00400 to 0.00355, saving model to lstmlevel-2-escrita.epoch16-loss0.00355.hdf5\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 4.1050e-05 - root_mean_squared_error: 0.0064 - mean_absolute_error: 0.0047 - val_loss: 1.2593e-05 - val_root_mean_squared_error: 0.0035 - val_mean_absolute_error: 0.0022\n",
            "Epoch 17/300\n",
            "844/848 [============================>.] - ETA: 0s - loss: 4.0794e-05 - root_mean_squared_error: 0.0064 - mean_absolute_error: 0.0047\n",
            "Epoch 17: val_root_mean_squared_error did not improve from 0.00355\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 4.0773e-05 - root_mean_squared_error: 0.0064 - mean_absolute_error: 0.0047 - val_loss: 2.3798e-05 - val_root_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0039\n",
            "Epoch 18/300\n",
            "846/848 [============================>.] - ETA: 0s - loss: 4.4069e-05 - root_mean_squared_error: 0.0066 - mean_absolute_error: 0.0049\n",
            "Epoch 18: val_root_mean_squared_error did not improve from 0.00355\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 4.4028e-05 - root_mean_squared_error: 0.0066 - mean_absolute_error: 0.0049 - val_loss: 1.8384e-05 - val_root_mean_squared_error: 0.0043 - val_mean_absolute_error: 0.0032\n",
            "Epoch 19/300\n",
            "847/848 [============================>.] - ETA: 0s - loss: 3.7499e-05 - root_mean_squared_error: 0.0061 - mean_absolute_error: 0.0045\n",
            "Epoch 19: val_root_mean_squared_error did not improve from 0.00355\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 3.7491e-05 - root_mean_squared_error: 0.0061 - mean_absolute_error: 0.0045 - val_loss: 3.8417e-05 - val_root_mean_squared_error: 0.0062 - val_mean_absolute_error: 0.0050\n",
            "Epoch 20/300\n",
            "844/848 [============================>.] - ETA: 0s - loss: 3.7981e-05 - root_mean_squared_error: 0.0062 - mean_absolute_error: 0.0046\n",
            "Epoch 20: val_root_mean_squared_error did not improve from 0.00355\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 3.8121e-05 - root_mean_squared_error: 0.0062 - mean_absolute_error: 0.0046 - val_loss: 3.5969e-05 - val_root_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0053\n",
            "Epoch 21/300\n",
            "845/848 [============================>.] - ETA: 0s - loss: 3.5879e-05 - root_mean_squared_error: 0.0060 - mean_absolute_error: 0.0044\n",
            "Epoch 21: val_root_mean_squared_error did not improve from 0.00355\n",
            "848/848 [==============================] - 11s 14ms/step - loss: 3.5872e-05 - root_mean_squared_error: 0.0060 - mean_absolute_error: 0.0044 - val_loss: 1.8348e-05 - val_root_mean_squared_error: 0.0043 - val_mean_absolute_error: 0.0033\n",
            "Epoch 22/300\n",
            "845/848 [============================>.] - ETA: 0s - loss: 3.8697e-05 - root_mean_squared_error: 0.0062 - mean_absolute_error: 0.0046\n",
            "Epoch 22: val_root_mean_squared_error did not improve from 0.00355\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 3.8669e-05 - root_mean_squared_error: 0.0062 - mean_absolute_error: 0.0046 - val_loss: 2.3599e-05 - val_root_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0039\n",
            "Epoch 23/300\n",
            "847/848 [============================>.] - ETA: 0s - loss: 3.5342e-05 - root_mean_squared_error: 0.0059 - mean_absolute_error: 0.0044\n",
            "Epoch 23: val_root_mean_squared_error did not improve from 0.00355\n",
            "848/848 [==============================] - 11s 14ms/step - loss: 3.5377e-05 - root_mean_squared_error: 0.0059 - mean_absolute_error: 0.0044 - val_loss: 1.7069e-05 - val_root_mean_squared_error: 0.0041 - val_mean_absolute_error: 0.0031\n",
            "Epoch 24/300\n",
            "844/848 [============================>.] - ETA: 0s - loss: 3.3110e-05 - root_mean_squared_error: 0.0058 - mean_absolute_error: 0.0042\n",
            "Epoch 24: val_root_mean_squared_error did not improve from 0.00355\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 3.3046e-05 - root_mean_squared_error: 0.0057 - mean_absolute_error: 0.0042 - val_loss: 1.3122e-05 - val_root_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0025\n",
            "Epoch 25/300\n",
            "847/848 [============================>.] - ETA: 0s - loss: 3.3495e-05 - root_mean_squared_error: 0.0058 - mean_absolute_error: 0.0043\n",
            "Epoch 25: val_root_mean_squared_error did not improve from 0.00355\n",
            "848/848 [==============================] - 12s 14ms/step - loss: 3.3478e-05 - root_mean_squared_error: 0.0058 - mean_absolute_error: 0.0043 - val_loss: 1.8016e-05 - val_root_mean_squared_error: 0.0042 - val_mean_absolute_error: 0.0031\n",
            "Epoch 26/300\n",
            "847/848 [============================>.] - ETA: 0s - loss: 3.0816e-05 - root_mean_squared_error: 0.0056 - mean_absolute_error: 0.0041\n",
            "Epoch 26: val_root_mean_squared_error did not improve from 0.00355\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 3.0814e-05 - root_mean_squared_error: 0.0056 - mean_absolute_error: 0.0041 - val_loss: 2.2745e-05 - val_root_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0040\n"
          ]
        }
      ],
      "source": [
        "model = get_model_2(params=params, input_shape=X_train_sequence.shape[2])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits = 6)\n",
        "\n",
        "filepath = 'lstmlevel.epoch{epoch:02d}-loss{val_root_mean_squared_error:.5f}.hdf5'\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "\tverbose=1,\n",
        "    monitor='val_root_mean_squared_error',\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_root_mean_squared_error',\n",
        "                                           \tmode='min',\n",
        "                                            patience=params[\"es_patience\"])\n",
        "\n",
        "history = model.fit(\n",
        "\tX_train_sequence,\n",
        "\ty_train_sequence,\n",
        "\tvalidation_data=(X_test_sequence, y_test_sequence),\n",
        "\tepochs=params[\"epochs\"],\n",
        "\tbatch_size=params[\"batch_size\"],\n",
        "\tverbose=1,\n",
        "\t# callbacks=[model_checkpoint_callback]\n",
        "\tcallbacks=[es_callback,model_checkpoint_callback]\n",
        ")\n",
        "\n",
        "# for train_index, test_index in tscv.split(X_train_sequence):\n",
        "# \tX_train_split, X_val_split = X_train_sequence[train_index], X_train_sequence[test_index]\n",
        "# \ty_train_split, y_val_split = y_train_sequence[train_index], y_train_sequence[test_index]\n",
        "\n",
        "# \tmodel.fit(\n",
        "# \t\tX_train_split,\n",
        "# \t\ty_train_split,\n",
        "# \t\tvalidation_data=(X_val_split, y_val_split),\n",
        "# \t\tepochs=params[\"epochs\"],\n",
        "# \t\tbatch_size=params[\"batch_size\"],\n",
        "# \t\tverbose=1,\n",
        "# \t\tcallbacks=[model_checkpoint_callback]\n",
        "# \t\t#callbacks=[es_callback,model_checkpoint_callback]\n",
        "# \t)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4dtmLAXDh7Xa"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}